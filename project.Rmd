
```{r load-packages, message = FALSE}
library(knitr)
library(tidyverse)
library(broom)
library(htmltools)
library(caret)
library(tidymodels)
library(schrute)
library(lubridate)
library(knitr)
library(openintro)
library(ROSE)
library(dplyr)
```

```{r setup, include = FALSE}
opts_chunk$set(echo=FALSE) # hide source code in the document
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
```
```{r}
drugsa <- read.csv("PUT DATALINK HERE")
```
```{r}
#Fills the "HardDrugs" column based on the presence of frequent drugs

fill_HardDrugs <- function(data) {
    for (i in 1:nrow(data)) {
      if (data$DSMCRIT[i] == -9) {
        
        s <- sum(c(data$sub1_bin[i], data$sub2_bin[i], data$sub3_bin[i]))
        
        if (s >= 2) {
          data$HardDrugs[i] <- 1}
        else{
          data$HardDrugs[i] <- 0}
    }
  }
  
  # Return the updated data
  return(data)
}
```
```{r}
# Performs data manipulation and calculates metrics related to the "HardDrugs" column
#Subset the dataset based on DSMCRIT values
subset <- drugsa[drugsa$DSMCRIT != -9, ]
#Assign values to "HardDrugs" based on DSMCRIT values
subset$HardDrugs[subset$DSMCRIT %in% c(1, 2, 3, 4, 7, 9, 10, 14, 15, 16, 17, 18, 19)] <- 0
subset$HardDrugs[subset$DSMCRIT %in% c(5, 6, 8, 11, 12, 13)] <- 1

hard_drug_codes <- c(3, 5, 7, 8, 9, 10, 12, 13,17,19)
#Update "sub1_bin", "sub2_bin", and "sub3_bin" columns
subset$sub1_bin[subset$SUB1 %in% c(1, 2, 4, 6, 11, 14, 15, 16, 18, -9)] <- 0
subset$sub1_bin[subset$SUB1 %in% hard_drug_codes] <- 1
subset$sub2_bin[subset$SUB2 %in% c(1, 2, 4, 6, 11, 14, 15, 16, 18, -9)] <- 0
subset$sub2_bin[subset$SUB2 %in% hard_drug_codes] <- 1
subset$sub3_bin[subset$SUB3 %in% c(1, 2, 4, 6, 11, 14, 15, 16, 18, -9)] <- 0
subset$sub3_bin[subset$SUB3 %in% hard_drug_codes] <- 1

# Calculate the sum of the values in the specified columns
sum_values <- rowSums(subset[, c("sub1_bin", "sub2_bin", "sub3_bin")])

# Create the new binary column
subset$check_hashlama <- ifelse(sum_values >= 2, 1, 0)

# Calculate the percentage of rows where the values in the columns are identical
identical_rows <- sum(subset$HardDrugs == subset$check_hashlama)
percentage_identical <- (identical_rows / nrow(subset)) * 100

# Print the result
cat("Percentage of identical rows:", percentage_identical, "%\n")


# Calculate the number of correct and incorrect values for each value (0 and 1)
correct_0 <- sum(subset$HardDrugs[subset$check_hashlama == 0] == 0)
correct_1 <- sum(subset$HardDrugs[subset$check_hashlama == 1] == 1)
incorrect_0 <- sum(subset$HardDrugs[subset$check_hashlama == 0] == 1)
incorrect_1 <- sum(subset$HardDrugs[subset$check_hashlama == 1] == 0)

# Calculate the percentages
percentage_correct_0 <- correct_0 / sum(subset$check_hashlama == 0) * 100
percentage_correct_1 <- correct_1 / sum(subset$check_hashlama == 1) * 100
percentage_incorrect_0 <- incorrect_0 / sum(subset$check_hashlama == 0) * 100
percentage_incorrect_1 <- incorrect_1 / sum(subset$check_hashlama == 1) * 100

# Create a table
table_data <- data.frame(
  Value = c(0, 1),
  Correct_Percentage = c(percentage_correct_0, percentage_correct_1),
  Incorrect_Percentage = c(percentage_incorrect_0, percentage_incorrect_1)
)

# Print the table
print(table_data)
```


```{r}
fdata <- drugsa[, !(names(drugsa) %in% c("CASEID", "ADMYR", "CBSA2010"))]

# Set the values to 1 where the DSMCRIT values match the specified conditions
fdata$HardDrugs[fdata$DSMCRIT %in% c(1, 2, 3, 4, 7, 9, 10, 14, 15, 16, 17, 18, 19)] <- 0
fdata$HardDrugs[fdata$DSMCRIT %in% c(5, 6, 8, 11, 12, 13)] <- 1


hard_drug_codes <- c(3, 5, 7, 8, 9, 10, 12, 13, 17, 19)

fdata$sub1_bin[fdata$SUB1 %in% c(1, 2, 4, 6, 11, 14, 15, 16, 18, -9) & fdata$DSMCRIT == -9] <- 0
fdata$sub1_bin[fdata$SUB1 %in% hard_drug_codes & fdata$DSMCRIT == -9] <- 1
fdata$sub2_bin[fdata$SUB2 %in% c(1, 2, 4, 6, 11, 14, 15, 16, 18, -9) & fdata$DSMCRIT == -9] <- 0
fdata$sub2_bin[fdata$SUB2 %in% hard_drug_codes & fdata$DSMCRIT == -9] <- 1
fdata$sub3_bin[fdata$SUB3 %in% c(1, 2, 4, 6, 11, 14, 15, 16, 18, -9) & fdata$DSMCRIT == -9] <- 0
fdata$sub3_bin[fdata$SUB3 %in% hard_drug_codes & fdata$DSMCRIT == -9] <- 1

# Calculate the sum of the values in the specified columns
sum_values <- rowSums(fdata[, c("sub1_bin", "sub2_bin", "sub3_bin")])

# Create the new binary column
fdata <- fill_HardDrugs(fdata)

```


```{r}
library(vcd)

# Get column names of drugs1 dataset
column_names <- colnames(fdata)

correlation <- vector("numeric", length(column_names))
for (i in seq_along(column_names)) {
  contingency_table <- table(fdata$HardDrugs, fdata[, i])
  correlation[i] <- assocstats(contingency_table)$cramer
}

# Sort correlations in descending order
sorted_correlation <- sort(correlation, decreasing = TRUE)

# Print correlations with column names
for (i in seq_along(sorted_correlation)) {
 print(paste0("Correlation with ", column_names[i], ": ", sorted_correlation[i]))
}
```

```{r}
library(vcd)

# Get column names of the dataset
column_names <- colnames(fdata)

# Create an empty matrix to store correlations
correlation_matrix <- matrix(0, ncol = length(column_names), nrow = length(column_names))
rownames(correlation_matrix) <- column_names
colnames(correlation_matrix) <- column_names

# Calculate Cramer's V correlation for each column combination
for (i in seq_along(column_names)) {
  for (j in seq_along(column_names)) {
    contingency_table <- table(fdata[, i], fdata[, j])
    correlation_matrix[i, j] <- assocstats(contingency_table)$cramer
  }
}

```
```{r}
selected_columns <- unlist(column_names[sorted_correlation >= 0.1])
selected_columns <- c(selected_columns, "HardDrugs")
selected_columns <- selected_columns[selected_columns != "DSMCRIT"]

unselected_columns <- column_names[sorted_correlation < 0.1]
unselected_columns <- c(unselected_columns, "DSMCRIT")
unselected_columns <- unselected_columns[unselected_columns != "HardDrugs"]
unselected_columns <- unlist(unselected_columns)
```

```{r}
# Set the seed for reproducibility
set.seed(123)

# Take a random sample of five percent of the dataset
sampled_data <- fdata %>%
  sample_frac(0.2)

```


```{r}

fdata_new <- select(sampled_data, selected_columns)
set.seed(666667)  # Set a seed for reproducibility
datasplit <- initial_split(fdata_new)
trainData <- training(datasplit)  # Training data
testData <- testing(datasplit)   # Testing/validation data
trainData <- trainData %>%
  mutate_all(factor)
testData <- testData %>%
  mutate_all(factor)

```

```{r}
drugs_mod <- logistic_reg() %>%
  set_engine("glm")

#GENDER, DETNLF, DAYWAIT, FREQ1, FREQ3, SUB1, SUB2, SUB3, SERVICES

drugs_rec <- recipe(HardDrugs ~ ., data = trainData) %>%
  step_rm(SUB1, SUB2, SUB3, DETNLF, DETCRIM, ROUTE3, FREQ3, FRSTUSE3, PREG, DAYWAIT, GENDER, METHFLG, SERVICES, METHFLG) %>%
  step_dummy(all_nominal(), -all_outcomes()) %>%
  step_zv(all_predictors())
  #step_backward()

drugs_wflow <- workflow() %>%
  add_model(drugs_mod) %>%
  add_recipe(drugs_rec)

logreg_fit <- drugs_wflow %>% 
  fit(data = trainData)


results <- testData %>% 
  bind_cols(logreg_fit %>% predict(new_data = testData, type = "prob"))%>% 
              bind_cols(logreg_fit %>% predict(new_data = testData, type = "class"))

```

```{r}
conf_mat(data = results, truth = HardDrugs, estimate = .pred_class)
```

```{r}
library(yardstick)
accuracy_val <- accuracy(data = results, truth = HardDrugs, estimate = .pred_class)
precision_val <- precision(data = results, truth = HardDrugs, estimate = .pred_class)
recall_val <- recall(data = results, truth = HardDrugs, estimate = .pred_class)
f_meas_val <- f_meas(data = results, truth = HardDrugs, estimate = .pred_class)


tidy(logreg_fit)

# Extract the value from accuracy_val tibble
accuracy_value <- accuracy_val$.estimate

# Extract the value from precision_val tibble
precision_value <- precision_val$.estimate

# Extract the value from recall_val tibble
recall_value <- recall_val$.estimate

# Extract the value from f_meas_val tibble
f_measure_value <- f_meas_val$.estimate

# Create a data frame to store the values
table_data <- data.frame(Test = c("Accuracy", "Precision", "Recall", "F-measure"),
                         Value = c(accuracy_value, precision_value, recall_value, f_measure_value))

# Print the table
print(table_data)
```

```{r}
# Calculate the number of rows to extract
num_rows <- ceiling(0.05 * nrow(results))

# Sort the results by descending order of ".pred_1" values
results_sorted <- results[order(-results$.pred_1), ]

# Extract the top 5% rows with highest ".pred_1" values
top_rows <- results_sorted[1:num_rows, ]

# Print the top rows
print(top_rows)
```
```{r, eval=FALSE}
library(ggplot2)


age_vector <- top_rows$NOPRIOR
age_counts <- table(age_vector)
age_percentages <- prop.table(age_counts) * 100
age_percentages <- sort(age_percentages, decreasing = TRUE)
age_table <- data.frame(Age = names(age_percentages), Percentage = age_percentages)

print(age_table)

res <- sampled_data %>%
  group_by(NOPRIOR, HardDrugs) %>%
  summarize(Percentage = n()) %>%
  group_by(NOPRIOR) %>%
  mutate(Percentage = Percentage / sum(Percentage) * 100) %>%
  pivot_wider(names_from = HardDrugs, values_from = Percentage, values_fill = 0)

# Print the result
print(res)

```
```{r}
columns <- colnames(top_rows)
columns <- columns[1:(length(columns) - 4)]
create_bar_graph <- function(data, columns) {
  for (column in columns) {
    print(ggplot(data, aes(x = .data[[column]])) + geom_bar())}
}
create_bar_graph(top_rows, columns)
```
